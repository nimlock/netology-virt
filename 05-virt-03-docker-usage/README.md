# Домашнее задание к занятию "5.3. Контейнеризация на примере Docker"

## Модуль 5. Виртуализация

### Студент: Иван Жиляев

## Обязательные задания

## Задача 1 

>Посмотрите на сценарий ниже и ответьте на вопрос:
>"Подходит ли в этом сценарии использование докера? Или лучше подойдет виртуальная машина, физическая машина? Или возможны разные варианты?"
>
>Детально опишите и обоснуйте свой выбор.
>
>--
>
>Сценарий:
>
>- Высоконагруженное монолитное java веб-приложение; 

Docker хорошо подойдёт для этого сценария. Он позволит легко горизонтально масштабировать сервис при необходимости, получить быструю беспростойную публикацию новых версий, своевременно балансировать нагрузку между нодами за счёт распределения трафика на балансировщике.

>- Go-микросервис для генерации отчетов;

Контейнер прекрасно подойдёт для этой задачи: он будет быстро создавать необходимое для микросервиса окружение и высвобождать ресурсы сразу после окончания его работы.

>- Nodejs веб-приложение;

Docker подойдёт; например, он будет полезен для разработки, чтобы протестить приложение на разных версиях Nodejs.

>- Мобильное приложение c версиями для Android и iOS;

И снова, Docker подойдёт; он избавит от проблемы с подгрузкой многочисленных зависимостей, тем более для сборки разных платформ - используем IaC (Infrastructure-as-Code) и получаем целый "зоопарк" окружений для работы с кодовой базой приложения при небольших запросах к аппаратному обеспечению и высокой скоростью организации рабочих/тестовых сред.

>- База данных postgresql используемая, как кэш;

Зависит от размера и необходимого быстродействия кэша; если требования высоки, то вместо виртуализации (и контейнеризации в частности) лучше разместить БД на физическом сервере.

>- Шина данных на базе Apache Kafka;

Контейнер позволит легко "расплодить" инстансы Apache Kafka - Docker подойдёт.

>- Очередь для Logstash на базе Redis;

Docker хорошо подходит для расположения очередей.

>- Elastic stack для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana;

Сам разработчик компонентов Elastic stack подготовил образы Docker, что уже говорит о возможности использования контейнеров. Однако, вероятно, что при ожидании значительных нагрузок для более удобного и явного распределения ресурсов между компонентами стоит расположить их на ВМ. 

>- Мониторинг-стек на базе prometheus и grafana;

Данный сценарий также поддерживает контейнеризацию, не вижу препятствий для её использования. 

>- Mongodb, как основное хранилище данных для java-приложения;

Так как MongoDB хорошо поддерживает репликацию и шардирование, то, пожалуй, нет причин не использовать контейнер.

>- Jenkins-сервер.

По идеологии контейнеризации в одном контейнере должен работать один процесс. Думаю, что для функционирования Jenkins-сервер использует гораздо больше процессов. Так что, в контейнер можно, но лучше расположить этот сервис в ВМ. 

## Задача 2 

>Сценарий выполнения задачи:
>
>- создайте свой репозиторий на докерхаб; 
>- выберете любой образ, который содержит апачи веб-сервер;
>- создайте свой форк образа;
>- реализуйте функциональность: 
>запуск веб-сервера в фоне с индекс-страницей, содержащей HTML-код ниже: 
>```
><html>
><head>
>Hey, Netology
></head>
><body>
><h1>I’m kinda DevOps now</h1>
></body>
></html>
>```
>Опубликуйте созданный форк в своем репозитории и предоставьте ответ в виде ссылки на докерхаб-репо.

Образ создан на основе прикреплённого [Dockerfile](Dockerfile) с вспомогательным файлом [index.html](index.html) и доступен на DockerHub [по ссылке](https://hub.docker.com/r/nimlock/netology-homework-5.3).

## Задача 3 

>- Запустите первый контейнер из образа centos c любым тэгом в фоновом режиме, подключив папку info из текущей рабочей директории на хостовой машине в /share/info контейнера;
>- Запустите второй контейнер из образа debian:latest в фоновом режиме, подключив папку info из текущей рабочей директории на хостовой машине в /info контейнера;
>- Подключитесь к первому контейнеру с помощью exec и создайте текстовый файл любого содержания в /share/info ;
>- Добавьте еще один файл в папку info на хостовой машине;
>- Подключитесь во второй контейнер и отобразите листинг и содержание файлов в /info контейнера.

Опишу команды, используемые для достижения результата:

- запуск первого контейнера; его постоянную работу обеспечим отправив основной процесс в "вечный сон":
  
  ```
  docker run -v $(pwd)/info:/share/info --rm -d --name container_1 centos sh -c 'sleep infinity'
  ```

- запуск второго контейнера:
  
  ```
  docker run -v $(pwd)/info:/info --rm -d --name container_2 debian:latest sh -c 'sleep infinity'
  ```

- создадим первый файл; используем конструкцию `sh -c 'command'` для уверенности в передаче команды контейнеру в желаемом виде:

  ```
  docker exec container_1 sh -c 'echo Hello, container_1 ! > /share/info/textfile'
  ```

- создадим второй файл с хостовой машины; приходится работать из-под sudo, т.к., как я понимаю, папка `info` на хосте была создана docker engine-ом, который работает под root и поэтому папка принадлежит root:

  ```
  sudo sh -c 'echo How are you, container_2 ? > $(pwd)/info/textfile_due'
  ```

- выводим желаемую информацию; в стремлении улучшить форматирование вывода используется запуск оболочки bash из-за необходимости вызова echo с ключом `-e` для работы со спец.знаками `\n`:

  ```
  docker exec container_2 bash -c '\
      echo -e "Listing of /info :\n"; \
      ls info/; \
      echo -e "\n\nConcatenate of all files in /info:\n"; \
      cat info/*'
  ```
